{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, accuracy_score, multilabel_confusion_matrix, ConfusionMatrixDisplay, confusion_matrix\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from src.data_processor.phase_3.prob1.v1 import  Phase3Prob1FeatureProcessor\n",
    "import numpy as np\n",
    "import gc\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_to_name = {'feature1': 'dur', 'feature2': 'proto', 'feature3': 'service', 'feature4': 'state', 'feature5': 'spkts', 'feature6': 'dpkts', 'feature7': 'sbytes', 'feature8': 'dbytes', 'feature9': 'sttl', 'feature10': 'dttl', 'feature11': 'sload', 'feature12': 'dload', 'feature13': 'sloss', 'feature14': 'dloss', 'feature15': 'sinpkt', 'feature16': 'dinpkt', 'feature17': 'sjit', 'feature18': 'djit', 'feature19': 'swin', 'feature20': 'stcpb', 'feature21': 'dtcpb', 'feature22': 'dwin', 'feature23': 'tcprtt', 'feature24': 'synack', 'feature25': 'ackdat', 'feature26': 'smean', 'feature27': 'dmean', 'feature28': 'trans_depth', 'feature29': 'response_body_len', 'feature30': 'ct_srv_src', 'feature31': 'ct_state_ttl', 'feature32': 'ct_dst_ltm', 'feature33': 'ct_src_dport_ltm', 'feature34': 'ct_dst_sport_ltm', 'feature35': 'ct_dst_src_ltm', 'feature36': 'is_ftp_login', 'feature37': 'ct_ftp_cmd', 'feature38': 'ct_flw_http_mthd', 'feature39': 'ct_src_ltm', 'feature40': 'ct_srv_dst', 'feature41': 'is_sm_ips_ports', 'label': 'label'}\n",
    "name_to_feat = {v:k for k, v in feat_to_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"F:/Data/MLOPS_2023/data_phase-3/phase-3/prob-1/raw_train.parquet\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61748, 42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"F:/Data/MLOPS_2023/UNSW_NB15_training-set.csv\")\n",
    "df3 = pd.read_csv(\"F:/Data/MLOPS_2023/UNSW_NB15_testing-set.csv\")\n",
    "df2 = pd.concat([df2, df3])\n",
    "del df3\n",
    "gc.collect()\n",
    "df2.drop(columns=['id','rate','attack_cat'],inplace=True)\n",
    "df2.drop_duplicates(inplace=True)\n",
    "df2.shape\n",
    "df2.columns = [name_to_feat[c] for c in df2.columns]\n",
    "df2 = df2.sample(frac=1, random_state=42, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "HyperParameters={'n_estimators':100,\n",
    "                 'learning_rate':0.1,\n",
    "                 'max_depth':32,\n",
    "                 'colsample_bytree':0.8,\n",
    "                 'subsample':0.8,\n",
    "                 'reg_alpha':1,\n",
    "                 'reg_lambda':0,\n",
    "                 'random_state':42}\n",
    "\n",
    "hyper_parameters = HyperParameters.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "61743    0\n",
       "61744    1\n",
       "61745    0\n",
       "61746    1\n",
       "61747    1\n",
       "Name: label, Length: 61748, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttraining's binary_logloss: 0.179684\ttraining's auc: 0.979738\tvalid_1's binary_logloss: 0.180093\tvalid_1's auc: 0.97959\n",
      "[100]\ttraining's binary_logloss: 0.165232\ttraining's auc: 0.98267\tvalid_1's binary_logloss: 0.169482\tvalid_1's auc: 0.981333\n",
      "[150]\ttraining's binary_logloss: 0.157164\ttraining's auc: 0.984671\tvalid_1's binary_logloss: 0.166166\tvalid_1's auc: 0.981941\n",
      "[200]\ttraining's binary_logloss: 0.150513\ttraining's auc: 0.986263\tvalid_1's binary_logloss: 0.163977\tvalid_1's auc: 0.982343\n",
      "[250]\ttraining's binary_logloss: 0.144989\ttraining's auc: 0.987597\tvalid_1's binary_logloss: 0.162806\tvalid_1's auc: 0.982587\n",
      "[300]\ttraining's binary_logloss: 0.139953\ttraining's auc: 0.988741\tvalid_1's binary_logloss: 0.16183\tvalid_1's auc: 0.982763\n",
      "fold 0 : 0.982763140286928\n",
      "[50]\ttraining's binary_logloss: 0.178196\ttraining's auc: 0.980009\tvalid_1's binary_logloss: 0.182774\tvalid_1's auc: 0.97879\n",
      "[100]\ttraining's binary_logloss: 0.164482\ttraining's auc: 0.982795\tvalid_1's binary_logloss: 0.173069\tvalid_1's auc: 0.980458\n",
      "[150]\ttraining's binary_logloss: 0.155899\ttraining's auc: 0.984774\tvalid_1's binary_logloss: 0.16941\tvalid_1's auc: 0.981177\n",
      "[200]\ttraining's binary_logloss: 0.149037\ttraining's auc: 0.9865\tvalid_1's binary_logloss: 0.167524\tvalid_1's auc: 0.981579\n",
      "[250]\ttraining's binary_logloss: 0.143834\ttraining's auc: 0.987757\tvalid_1's binary_logloss: 0.166402\tvalid_1's auc: 0.981804\n",
      "[300]\ttraining's binary_logloss: 0.138625\ttraining's auc: 0.988968\tvalid_1's binary_logloss: 0.1655\tvalid_1's auc: 0.981969\n",
      "fold 1 : 0.9819693431069441\n",
      "[50]\ttraining's binary_logloss: 0.179125\ttraining's auc: 0.979828\tvalid_1's binary_logloss: 0.178484\tvalid_1's auc: 0.979723\n",
      "[100]\ttraining's binary_logloss: 0.165635\ttraining's auc: 0.982535\tvalid_1's binary_logloss: 0.169408\tvalid_1's auc: 0.981163\n",
      "[150]\ttraining's binary_logloss: 0.15738\ttraining's auc: 0.984561\tvalid_1's binary_logloss: 0.165879\tvalid_1's auc: 0.981891\n",
      "[200]\ttraining's binary_logloss: 0.150594\ttraining's auc: 0.986144\tvalid_1's binary_logloss: 0.163229\tvalid_1's auc: 0.982433\n",
      "[250]\ttraining's binary_logloss: 0.144538\ttraining's auc: 0.987605\tvalid_1's binary_logloss: 0.161863\tvalid_1's auc: 0.982712\n",
      "[300]\ttraining's binary_logloss: 0.139585\ttraining's auc: 0.988818\tvalid_1's binary_logloss: 0.16128\tvalid_1's auc: 0.982792\n",
      "fold 2 : 0.9827915748021985\n",
      "[50]\ttraining's binary_logloss: 0.178859\ttraining's auc: 0.979889\tvalid_1's binary_logloss: 0.181118\tvalid_1's auc: 0.979212\n",
      "[100]\ttraining's binary_logloss: 0.164267\ttraining's auc: 0.98283\tvalid_1's binary_logloss: 0.170962\tvalid_1's auc: 0.980998\n",
      "[150]\ttraining's binary_logloss: 0.15619\ttraining's auc: 0.98483\tvalid_1's binary_logloss: 0.16755\tvalid_1's auc: 0.9817\n",
      "[200]\ttraining's binary_logloss: 0.149736\ttraining's auc: 0.986382\tvalid_1's binary_logloss: 0.165489\tvalid_1's auc: 0.98211\n",
      "[250]\ttraining's binary_logloss: 0.144142\ttraining's auc: 0.987682\tvalid_1's binary_logloss: 0.164144\tvalid_1's auc: 0.982364\n",
      "[300]\ttraining's binary_logloss: 0.13913\ttraining's auc: 0.988858\tvalid_1's binary_logloss: 0.163348\tvalid_1's auc: 0.982519\n",
      "fold 3 : 0.9825187720574874\n",
      "[50]\ttraining's binary_logloss: 0.177878\ttraining's auc: 0.980194\tvalid_1's binary_logloss: 0.18815\tvalid_1's auc: 0.977019\n",
      "[100]\ttraining's binary_logloss: 0.16297\ttraining's auc: 0.983108\tvalid_1's binary_logloss: 0.177066\tvalid_1's auc: 0.979196\n",
      "[150]\ttraining's binary_logloss: 0.154786\ttraining's auc: 0.985067\tvalid_1's binary_logloss: 0.173317\tvalid_1's auc: 0.980106\n",
      "[200]\ttraining's binary_logloss: 0.148166\ttraining's auc: 0.986663\tvalid_1's binary_logloss: 0.17148\tvalid_1's auc: 0.98056\n",
      "[250]\ttraining's binary_logloss: 0.142357\ttraining's auc: 0.988004\tvalid_1's binary_logloss: 0.170095\tvalid_1's auc: 0.98085\n",
      "[300]\ttraining's binary_logloss: 0.13739\ttraining's auc: 0.989166\tvalid_1's binary_logloss: 0.169194\tvalid_1's auc: 0.981041\n",
      "fold 4 : 0.9810411752562016\n",
      "0.9822168011019519 0.0006577795007465533\n"
     ]
    }
   ],
   "source": [
    "processor = Phase3Prob1FeatureProcessor()\n",
    "new_df = processor.fit_transform(df2)\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "FEATURES = processor.data_features['features']\n",
    "categorical = processor.data_features['categorical_features']\n",
    "TARGET = 'label'\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "models = []\n",
    "scores = []\n",
    "oofs = np.zeros(df2.shape[0])\n",
    "for i, (train_idx, valid_idx) in enumerate(kfold.split(new_df, df2['label'])):\n",
    "    X_train = new_df.iloc[train_idx][FEATURES]\n",
    "    X_valid = new_df.iloc[valid_idx][FEATURES]\n",
    "    y_train = df2.iloc[train_idx][TARGET]\n",
    "    y_valid = df2.iloc[valid_idx][TARGET]\n",
    "    \n",
    "    # scaler = StandardScaler()\n",
    "    # scaler = scaler.fit(X_train[num_col])\n",
    "    # X_train[num_col] = scaler.transform(X_train[num_col])\n",
    "    # X_valid[num_col] = scaler.transform(X_valid[num_col])\n",
    "    # model = LogisticRegression(max_iter=7000)\n",
    "    # model.fit(X_train, y_train)\n",
    "    model = LGBMClassifier(**hyper_parameters)\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              categorical_feature=categorical,\n",
    "              eval_metric=[\"logloss\", \"auc\"],\n",
    "              early_stopping_rounds=50,\n",
    "              verbose=50)\n",
    "    models.append(model)\n",
    "    y_pred_proba = model.predict_proba(X_valid)[:,1]\n",
    "    oofs[valid_idx] = y_pred_proba\n",
    "\n",
    "    print(f\"fold {i} : {roc_auc_score(y_valid, y_pred_proba)}\")\n",
    "    scores.append(roc_auc_score(y_valid, y_pred_proba))\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's binary_logloss: 0.179271\tvalid_0's auc: 0.979686\n",
      "[100]\tvalid_0's binary_logloss: 0.164923\tvalid_0's auc: 0.982563\n",
      "[150]\tvalid_0's binary_logloss: 0.157476\tvalid_0's auc: 0.984384\n",
      "[200]\tvalid_0's binary_logloss: 0.151503\tvalid_0's auc: 0.985833\n",
      "[250]\tvalid_0's binary_logloss: 0.146402\tvalid_0's auc: 0.987052\n",
      "[300]\tvalid_0's binary_logloss: 0.142013\tvalid_0's auc: 0.988075\n"
     ]
    }
   ],
   "source": [
    "gmodel = LGBMClassifier(**hyper_parameters)\n",
    "gmodel.fit(new_df[FEATURES], df2[TARGET],\n",
    "           eval_set=[(new_df[FEATURES],df2[TARGET])],\n",
    "           eval_metric=[\"logloss\", \"auc\"],\n",
    "           categorical_feature=categorical,\n",
    "           verbose=50)\n",
    "\n",
    "with open(f'../checkpoints/phase-3/prob-1/v1.pkl','wb') as file:\n",
    "    pickle.dump(gmodel, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
